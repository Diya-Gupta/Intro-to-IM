I enjoyed reading this article because this was the first time that I had heard of a female who had so much to contribute to the Apollo mission! It speaks a lot about how male-centric the field was and, to a certain extent, still is considering that not a lot of people working in software know about Hamilton and her contributions. 

One point in the article that I found really interesting was how everyone, except for Hamilton, assumed that humans are perfect and that there is no need to account for any sort of human error. The fact that these were all super experienced and knowledgable people makes it even more ironic. They put too much confidence in the human brain and just took it as a matter of fact that any errors that would happen would be commited by the machine and that the humans dealing with everything related to the project would never be responsible for an error. Turns out, even though Hamilton included a note to prevent the error from being commited by a human, it still happened and a solution needed to be found with not a lot of time to think of one. 

This reminded me of Don Norman's approach of making human centric design and affordances. He had mentioned in his book how engineers cannot always understand the design element of their machines and that they need a designer to understandt that. An engineer's solution to this problem would be adding code, like Hamilton wanted, while a designer's solution might have been to change the affordance in some manner so that triggering the wrong programme would not happen that easily. I am not familiar with these things so I can't say for sure but it is interesting to see how a simple assumption that humans know how to interact with machines and that they understand machines enough to not make mistakes could go so wrong.
